{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# Utilização de Algorítmos de Machine Learning para Identificação de Empresas \"de Fachada\" em Operações de Importação\n",
    "TCC PUC Minas - LUCIANA MACEDO RODRIGUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTEBOOK 4 - MACHINE LEARNING - CLASSIFICAÇÃO\n",
    "\n",
    "### 1 - Configurações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando o Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install  pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os pacotes necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n",
    "from pycaret.utils import check_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Leitura do dataframe final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('arquivos/df_final.csv', sep = ',')\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensões do dataframe final\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo de informações do dataframe final \n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigindo o tipo da variável alvo\n",
    "df_final = df_final.astype({'TARGET': 'object'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Isolamento de uma amostra para predições simulando um cenário real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando 5% da amostra aleatóriamente\n",
    "data = df_final.sample(frac=0.95, random_state=786)\n",
    "data_pred = df_final.drop(data.index)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "data_pred.reset_index(inplace=True, drop=True)\n",
    "print('Dados para Modelagem (data) correspondendo a 95% do df_final: ' + str(data.shape))\n",
    "print('Dados para Predições (data_pred) correspondendo a 5% do df_final: ' + str(data_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como não há estratificação dessa amostra, assim como no mundo real, ela poderá não ter nenhum positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Configurando o ambiente no Pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de rodar os algorítmos de classificação no Pycaret é preciso chamar a função 'setup' que inicializa o ambiente de treinamento e cria o 'pipeline' de transformação.\n",
    "\n",
    "Para referência aos testes realizados para a seleção de parâmetros de setup consultar o NOTEBOOK05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_exp = setup(data = data,\n",
    "                   target = 'TARGET',\n",
    "                   session_id=123,\n",
    "                   silent = True,\n",
    "                   ordinal_features = {'EMP_PORTE':['ME','EPP','DEMAIS']}, \n",
    "                   fix_imbalance = True,\n",
    "                   high_cardinality_features = ['UF_EMP'],\n",
    "                   ignore_low_variance = True,\n",
    "                   feature_ratio = True,\n",
    "                   remove_multicollinearity = True, \n",
    "                   multicollinearity_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Comparação e escolha dos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Pycaret fornece uma comparação das principais métricas baseadas na acurácia, entretanto para modelos de classificação nos quais as classes da variável alvo apresentam-se muito desbalanceadas, como é o caso em nosso estudo, não devemos utilizar essa métrica.\n",
    "\n",
    "Métricas melhores para o nosso caso seriam: Precision, Recall, F1 Score e AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparando modelos com base no F1 + Recall\n",
    "best_model = compare_models(n_select = 3, sort = 'F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os modelos testados apresentam F1 Score bem abaixo do ideal. \n",
    "\n",
    "Como, para nosso objetivo, os \"Falsos Negativos\" são considerados mais prejudiciais que os \"Falsos Positivos\", analisaremos os modelos com base no F1 Score com maior Revocação (Recall), buscando os testar os modelos com níveis mais aceitáveis para o problema estudado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = compare_models(include = ['gbc', 'ada', 'knn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o modelo Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = create_model('gbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o modelo Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = create_model('ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o modelo K Neighbors Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = create_model('knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 -  Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Gradient Boosting Classifier\n",
    "plot_model(gbc, plot = 'confusion_matrix', plot_kwargs = {'percent' : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Ada Boost Classifier\n",
    "plot_model(ada, plot = 'confusion_matrix', plot_kwargs = {'percent' : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo K Neighbors Classifier\n",
    "plot_model(knn, plot = 'confusion_matrix', plot_kwargs = {'percent' : True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Análises globais de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação global Gradient Boosting Classifier\n",
    "evaluate_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(gbc, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(gbc, plot = 'learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(gbc, plot = 'feature_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(gbc, plot = 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação Ada Boost Classifier\n",
    "evaluate_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ada, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ada, plot = 'learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(ada, plot = 'feature_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ada, plot = 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação K Neighbors Classifier\n",
    "evaluate_model(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(knn, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(knn, plot = 'learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(knn, plot = 'class_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Tunning do modelo escolhido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_ada = tune_model(ada, optimize = 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparando os modelos\n",
    "# default model\n",
    "print(ada)\n",
    "\n",
    "# tuned model\n",
    "print(tuned_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_ada, plot = 'confusion_matrix', plot_kwargs = {'percent' : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_ada, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tuned_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_ada, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_ada, plot = 'learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(tuned_ada, plot = 'feature_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_ada, plot = 'class_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - Predição utilizando o modelo escolhido - Dados para modelagem ('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição na amostra de teste (data) - Ada Boost Classifier Tunned\n",
    "predict_model(tuned_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 - Finalizando o modelo para implantação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuned_ada = finalize_model(tuned_ada)\n",
    "print(final_tuned_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 - Predição utilizando o modelo escolhido - Dados para predição ('data_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_predictions = predict_model(final_tuned_ada, data=data_pred)\n",
    "unseen_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando erros e acertos da predição\n",
    "freq_acertos = unseen_predictions.groupby(['TARGET', 'Label']).size()\n",
    "freq_acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a taxa de Recall do modelo nos dados para predição\n",
    "recall = check_metric(unseen_predictions['TARGET'], unseen_predictions['Label'], metric = 'Recall')\n",
    "print('A taxa de recall do modelo nos dados para predição foi de', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o F1 Score do modelo nos dados para predição\n",
    "F1 = check_metric(unseen_predictions['TARGET'], unseen_predictions['Label'], metric = 'F1')\n",
    "print('O F1 Score do modelo nos dados para predição foi de', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a taxa de Precision do modelo nos dados para predição\n",
    "precision = check_metric(unseen_predictions['TARGET'], unseen_predictions['Label'], metric = 'Precision')\n",
    "print('A taxa de precisão do modelo nos dados para predição foi de', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13 - Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(final_tuned_ada,'Final Teste ADA TUNED Model 12Abr2022')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
